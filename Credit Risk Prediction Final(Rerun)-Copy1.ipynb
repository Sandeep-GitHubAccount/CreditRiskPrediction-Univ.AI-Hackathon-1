{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "defpred_train = pd.read_csv('Training Data.csv')\n",
    "defpred_test = pd.read_csv('Test Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "defpred_train['married'] = defpred_train['married'] == 'single'\n",
    "defpred_train[\"married\"] = defpred_train['married'].astype(int)\n",
    "\n",
    "defpred_test['married'] = defpred_test['married'] == 'single'\n",
    "defpred_test[\"married\"] = defpred_test['married'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defpred_train['car_ownership'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "defpred_train['house_ownership'] = defpred_train['house_ownership'].map({'rented': 0, 'norent_noown': 1, \n",
    "                                                                         'owned' : 2})\n",
    "\n",
    "defpred_test['house_ownership'] = defpred_test['house_ownership'].map({'rented': 0, 'norent_noown': 1, \n",
    "                                                                         'owned' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "defpred_train['car_ownership'] = defpred_train['car_ownership'].map({'no': 0, 'yes': 1, })\n",
    "defpred_test['car_ownership'] = defpred_test['car_ownership'].map({'no': 0, 'yes': 1, })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = defpred_train[['income','age','experience','married','house_ownership','car_ownership',\n",
    "                            'current_job_years','current_house_years','risk_flag']]\n",
    "#train_label = defpred_train[['risk_flag']]\n",
    "\n",
    "test_data = defpred_test[['income','age','experience','married','house_ownership','car_ownership',\n",
    "                            'current_job_years','current_house_years']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.iloc[:,:-1]\n",
    "y = train_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Some More Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from collections import Counter\n",
    "#from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 221004, 1: 221004})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Data Augmentation For Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SVMSMOTE()\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 221004, 1: 221004})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303835</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7574516</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3991815</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6256451</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5768871</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    income  age  experience  married  house_ownership  car_ownership  \\\n",
       "0  1303835   23           3        1                0              0   \n",
       "1  7574516   40          10        1                0              0   \n",
       "2  3991815   66           4        0                0              0   \n",
       "3  6256451   41           2        1                0              1   \n",
       "4  5768871   47          11        1                0              0   \n",
       "\n",
       "   current_job_years  current_house_years  \n",
       "0                  3                   13  \n",
       "1                  9                   13  \n",
       "2                  4                   10  \n",
       "3                  2                   12  \n",
       "4                  3                   14  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X_test = preprocessing.normalize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_X_test = preprocessing.scale(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_train_std = sc.transform(X)\n",
    "X_test_std = sc.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Ensemble Model (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1000, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt'\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model1 = RandomForestClassifier(n_estimators=1000, \n",
    "#                                bootstrap = True,\n",
    "#                                max_features = 'sqrt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = []\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_score1 = []\n",
    "# k = 10\n",
    "# kf = KFold(n_splits=k, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.9357028121535712, 0.9449559964706681, 0.870116060722608, 0.8946403927512953, 0.8819257482862378, 0.6079500463790412, 0.940159724893102, 0.9414040406325649, 0.9838461538461538, 0.9950904977375565]\n",
      "Avg accuracy : 0.89957914738728\n"
     ]
    }
   ],
   "source": [
    "# c = 0\n",
    "# for train_index , test_index in kf.split(X):\n",
    "#     X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "#     y_train , y_test = y[train_index] , y[test_index]\n",
    "    \n",
    "# #     if c == 2:  \n",
    "#     model1.fit(X_train,y_train)\n",
    "#     pred_values = model1.predict(X_test)\n",
    "     \n",
    "#     acc = accuracy_score(pred_values , y_test)\n",
    "#     acc_score1.append(acc)\n",
    "# #         acc1 = acc\n",
    "# #     c += 1\n",
    "     \n",
    "# avg_acc_score = sum(acc_score1)/k\n",
    "# #print('best accuracy: {}'.format(acc))\n",
    "# print('accuracy of each fold - {}'.format(acc_score1))\n",
    "# print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.9357028121535712, 0.9449559964706681, 0.870116060722608, 0.8946403927512953, 0.8862469174905545, 0.6341937965204407, 0.8636229949548653, 0.9632813737245763, 0.9981221719457014, 0.9971945701357466]\n",
      "Avg accuracy : 0.8988077086870027\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = standardized_X[train_index,:],standardized_X[test_index,:]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "    \n",
    "#     if c == 2:  \n",
    "    model.fit(X_train,y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "     \n",
    "    acc = accuracy_score(pred_values , y_test)\n",
    "    acc_score.append(acc)\n",
    "#         acc1 = acc\n",
    "#     c += 1\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    "#print('best accuracy: {}'.format(acc))\n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(standardized_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frame Creation and Saving the results of prediction in CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_flag = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_flag['risk_flag'] = pd.Series(pred)\n",
    "risk_flag.insert(0, 'id',risk_flag.index + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_flag.to_csv('Prediction Dataset_finall.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_grid_search(clf, X_train_hp, y_train_hp, X_val_hp, y_val_hp, hyperparams, fixed_hyperparams={}):\n",
    "    '''\n",
    "    Conduct hyperparameter grid search on hold out validation set. Use holdout validation.\n",
    "    Hyperparameters are input as a dictionary mapping each hyperparameter name to the\n",
    "    range of values they should iterate over. Use the cindex function as your evaluation\n",
    "    function.\n",
    "\n",
    "    Input:\n",
    "        clf: sklearn classifier\n",
    "        X_train_hp (dataframe): dataframe for training set input variables\n",
    "        y_train_hp (dataframe): dataframe for training set targets\n",
    "        X_val_hp (dataframe): dataframe for validation set input variables\n",
    "        y_val_hp (dataframe): dataframe for validation set targets\n",
    "        hyperparams (dict): hyperparameter dictionary mapping hyperparameter\n",
    "                            names to range of values for grid search\n",
    "        fixed_hyperparams (dict): dictionary of fixed hyperparameters that\n",
    "                                  are not included in the grid search\n",
    "\n",
    "    Output:\n",
    "        best_estimator (sklearn classifier): fitted sklearn classifier with best performance on\n",
    "                                             validation set\n",
    "        best_hyperparams (dict): hyperparameter dictionary mapping hyperparameter\n",
    "                                 names to values in best_estimator\n",
    "    '''\n",
    "    best_estimator = None\n",
    "    best_hyperparams = {}\n",
    "    \n",
    "    # hold best running score\n",
    "    best_score = 0.0\n",
    "\n",
    "    # get list of param values\n",
    "    lists = hyperparams.values()\n",
    "    \n",
    "    # get all param combinations\n",
    "    param_combinations = list(itertools.product(*lists))\n",
    "    total_param_combinations = len(param_combinations)\n",
    "\n",
    "    # iterate through param combinations\n",
    "    for i, params in enumerate(param_combinations, 1):\n",
    "        # fill param dict with params\n",
    "        param_dict = {}\n",
    "        for param_index, param_name in enumerate(hyperparams):\n",
    "            param_dict[param_name] = params[param_index]\n",
    "            \n",
    "        # create estimator with specified params\n",
    "        estimator = clf(**param_dict, **fixed_hyperparams)\n",
    "\n",
    "        # fit estimator\n",
    "        estimator.fit(X_train_hp, y_train_hp)\n",
    "        \n",
    "        # get predictions on validation set\n",
    "        preds = estimator.predict(X_val_hp)\n",
    "        \n",
    "        # compute cindex for predictions\n",
    "        print(preds)\n",
    "        print(y_val_hp)\n",
    "        estimator_score = accuracy_score(preds, y_val_hp)\n",
    "\n",
    "        print(f'[{i}/{total_param_combinations}] {param_dict}')\n",
    "        print(f'Val Accuracy: {estimator_score}\\n')\n",
    "\n",
    "        # if new high score, update high score, best estimator\n",
    "        # and best params \n",
    "        if estimator_score >= best_score:\n",
    "                best_score = estimator_score\n",
    "                best_estimator = estimator\n",
    "                best_hyperparams = param_dict\n",
    "\n",
    "    # add fixed hyperparamters to best combination of variable hyperparameters\n",
    "    best_hyperparams.update(fixed_hyperparams)\n",
    "    \n",
    "    return best_estimator, best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_grid_search(X_train_dropped, y_train_dropped, X_val_dropped, y_val_dropped):\n",
    "\n",
    "    # Define ranges for the chosen random forest hyperparameters \n",
    "    hyperparams = {\n",
    "        \n",
    "        ### START CODE HERE (REPLACE array values with your code) ###\n",
    "\n",
    "        # how many trees should be in the forest (int)\n",
    "        'n_estimators': [10],\n",
    "\n",
    "        # the maximum depth of trees in the forest (int)\n",
    "        \n",
    "        'max_depth': [200],\n",
    "        \n",
    "        # the minimum number of samples in a leaf as a fraction\n",
    "        # of the total number of samples in the training set\n",
    "        # Can be int (in which case that is the minimum number)\n",
    "        # or float (in which case the minimum is that fraction of the\n",
    "        # number of training set samples)\n",
    "        'min_samples_leaf': [1],\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "    }\n",
    "\n",
    "    \n",
    "    fixed_hyperparams = {\n",
    "        'random_state': 10,\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestClassifier\n",
    "\n",
    "    best_rf, best_hyperparams = holdout_grid_search(rf, X_train_dropped, y_train_dropped,\n",
    "                                                    X_val_dropped, y_val_dropped, hyperparams,\n",
    "                                                    fixed_hyperparams)\n",
    "\n",
    "    print(f\"Best hyperparameters:\\n{best_hyperparams}\")\n",
    "\n",
    "    \n",
    "    y_train_best = best_rf.predict(X_train_dropped)\n",
    "    print(f\"Train Accuracy: {accuracy_score(y_train_best, y_train_dropped)}\")\n",
    "\n",
    "    y_val_best = best_rf.predict(X_val_dropped)\n",
    "    print(f\"Val Accuracy: {accuracy_score(y_val_best, y_val_dropped)}\")\n",
    "    \n",
    "    # add fixed hyperparamters to best combination of variable hyperparameters\n",
    "    best_hyperparams.update(fixed_hyperparams)\n",
    "    \n",
    "    return best_rf, best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 1]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        1\n",
      "4        1\n",
      "5        0\n",
      "6        0\n",
      "7        0\n",
      "8        0\n",
      "9        0\n",
      "10       0\n",
      "11       0\n",
      "12       0\n",
      "13       0\n",
      "14       1\n",
      "15       0\n",
      "16       0\n",
      "17       1\n",
      "18       0\n",
      "19       0\n",
      "20       0\n",
      "21       0\n",
      "22       0\n",
      "23       0\n",
      "24       0\n",
      "25       0\n",
      "26       0\n",
      "27       0\n",
      "28       1\n",
      "29       0\n",
      "        ..\n",
      "44171    0\n",
      "44172    0\n",
      "44173    1\n",
      "44174    0\n",
      "44175    0\n",
      "44176    1\n",
      "44177    0\n",
      "44178    1\n",
      "44179    0\n",
      "44180    0\n",
      "44181    0\n",
      "44182    0\n",
      "44183    0\n",
      "44184    0\n",
      "44185    0\n",
      "44186    0\n",
      "44187    0\n",
      "44188    0\n",
      "44189    0\n",
      "44190    0\n",
      "44191    0\n",
      "44192    0\n",
      "44193    0\n",
      "44194    0\n",
      "44195    0\n",
      "44196    1\n",
      "44197    0\n",
      "44198    0\n",
      "44199    1\n",
      "44200    1\n",
      "Name: risk_flag, Length: 44201, dtype: int64\n",
      "[1/1] {'n_estimators': 10, 'max_depth': 200, 'min_samples_leaf': 1}\n",
      "Val Accuracy: 0.9357028121535712\n",
      "\n",
      "Best hyperparameters:\n",
      "{'n_estimators': 10, 'max_depth': 200, 'min_samples_leaf': 1, 'random_state': 10}\n",
      "Train Accuracy: 0.9575120598682275\n",
      "Val Accuracy: 0.9357028121535712\n"
     ]
    }
   ],
   "source": [
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = X_train_std[train_index,:],X_train_std[test_index,:]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "    best_rf, best_hyperparams = random_forest_grid_search(X_train, y_train, X_test, y_test)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
